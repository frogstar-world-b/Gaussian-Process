{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood \n",
    "One way to obtain inference for the hyper-parameters of the Gaussian process is through maximum likelihood estimation (MLE). Recall, the distribution of $y$ given $x$ and the parameters $\\mu, \\sigma^2, \\ell$ is a multivariate normal. \n",
    "\n",
    "$$\n",
    "\\color{blue}{\n",
    "p(y|x, \\mu, \\sigma^2, \\ell) = \n",
    "(2\\pi)^{-\\frac{n}{2}} |\\Sigma_x|^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}\\left(y - \\mu \\right)^{T}\\Sigma^{-1}_x\\left(y - \\mu \\right) \\right)}\n",
    "$$\n",
    "\n",
    "The likelihood treats the parameters as the unknown part of the function given the known values of $y$ and $x$, \n",
    "\n",
    "$$\n",
    "\\color{blue}{\n",
    "\\mathcal{L}(\\mu, \\sigma^2, \\ell | y, x) = \n",
    "(2\\pi)^{-\\frac{n}{2}} |\\Sigma_x|^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}\\left(y - \\mu \\right)^{T}\\Sigma^{-1}_x\\left(y - \\mu \\right) \\right)}\n",
    "$$\n",
    "$$\n",
    "\\color{white}{\n",
    "\\mathcal{L}(\\mu, \\sigma^2, \\ell | y, x)}\\color{blue}{\n",
    "\\mathcal{L}(\\mu, \\sigma^2, \\ell | y, x)\\propto |\\Sigma_x|^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}\\left(y - \\mu \\right)^{T}\\Sigma^{-1}_x\\left(y - \\mu \\right) \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, the log likelihood is given by\n",
    "$$\n",
    "\\color{blue}{\n",
    "\\log p(y|x, \\mu, \\sigma^2, \\ell) \\propto \n",
    "-\\frac{1}{2}\\log|\\Sigma_x| - \\left(\\frac{1}{2}\\left(y - \\mu \\right)^{T}\\Sigma^{-1}_x\\left(y - \\mu \\right) \\right)}\n",
    "$$\n",
    "$$\n",
    "\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\;\\;\\;\\;     \n",
    "\\color{blue}{\\propto -\\log|\\Sigma_x| - \\left(y - \\mu \\right)^{T}\\Sigma^{-1}_x\\left(y - \\mu \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Prediction (aka interpolation)\n",
    "\n",
    "We can relate the sample we used to fit the GP model to the predicted values using this multivariate normal distribution:\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\color{blue}{\n",
    "\\begin{pmatrix}\n",
    "y \\\\\n",
    "y^{pred} \\\\\n",
    "\\end{pmatrix}\n",
    "\\sim\n",
    "\\mathcal N_{n+m} \\left( \n",
    "\\begin{pmatrix}\n",
    "\\,\n",
    "\\mu(x) \\\\\n",
    "\\mu\\left(x^{pred}\\right) \\\\\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "K(x, x) & K(x, x^{pred})\\\\\n",
    "K(x^{pred}, x) & K(x^{pred}, x^{pred}) \\\\\n",
    "\\end{pmatrix}\n",
    "\\,\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "Then we can obtain the conditional distribution $\\color{blue}{y^{pred}| y, \\mu ,\\sigma^2, \\ell}$, which will be a multivariate normal with mean (expectation) and covariance given by\n",
    "\n",
    "$$\\color{blue}{\\mathbb E = \\mu\\left(x^{pred}\\right) + K(x^{pred}, x)K(x, x)^{-1}\\left[y - \\mu(x)\\right]}\n",
    "$$\n",
    "\n",
    "$$\\color{blue}{\\mathbb {Cov} = K(x^{pred}, x^{pred}) - K(x^{pred}, x)\\,K(x, x)^{-1}\\, K(x, x^{pred})}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
